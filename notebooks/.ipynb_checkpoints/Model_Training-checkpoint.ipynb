{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV data into the pandas dataframe\n",
    "file = '../data/data.csv'\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's replace the label column values to 0 for normal and 1 for others!\n",
    "\n",
    "LABELS = data[\"label\"].unique() # Get Unique Values of label column\n",
    "LABELS = [label for label in LABELS if label != \"normal\"] #All labels other than Normal!\n",
    "\n",
    "data[\"label\"].replace(['normal'], 0, inplace=True)\n",
    "data[\"label\"].replace(LABELS, 1 , inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(\"None\") # fill all the empty hosts with 0\n",
    "\n",
    "#Now let's encode all the columns which are not float or int e.g. sourceIP, MAC to make it possible for model to interpret\n",
    "columnsToEncode = list(data.select_dtypes(include=['category', 'object']))  \n",
    "            \n",
    "le = LabelEncoder() # use label encoder from sklearn\n",
    "\n",
    "for feature in columnsToEncode:\n",
    "    try:\n",
    "        data[feature] = le.fit_transform(data[feature])\n",
    "        #print(data[feature])\n",
    "    except:\n",
    "        print ('error' + feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>sourceMac</th>\n",
       "      <th>sourceIp</th>\n",
       "      <th>destIp</th>\n",
       "      <th>destMac</th>\n",
       "      <th>sourcePort</th>\n",
       "      <th>destPort</th>\n",
       "      <th>host</th>\n",
       "      <th>kIn</th>\n",
       "      <th>kOut</th>\n",
       "      <th>...</th>\n",
       "      <th>outPacketsNo</th>\n",
       "      <th>protocol</th>\n",
       "      <th>urgent</th>\n",
       "      <th>ack</th>\n",
       "      <th>push</th>\n",
       "      <th>reset</th>\n",
       "      <th>syn</th>\n",
       "      <th>fin</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>19357</td>\n",
       "      <td>8000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.015625</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1939</td>\n",
       "      <td>8000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.015625</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>19668</td>\n",
       "      <td>8000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.507813</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>19807</td>\n",
       "      <td>8000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.507813</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>19851</td>\n",
       "      <td>8000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.507813</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid  sourceMac  sourceIp  destIp  destMac  sourcePort  destPort  host  kIn  \\\n",
       "0    0          0         2      15        5       19357      8000     3  0.0   \n",
       "1    0          0         2      15        5        1939      8000     3  0.0   \n",
       "2    0          0         2      15        5       19668      8000     3  0.0   \n",
       "3    0          0         2      15        5       19807      8000     3  0.0   \n",
       "4    0          0         2      15        5       19851      8000     3  0.0   \n",
       "\n",
       "       kOut  ...  outPacketsNo  protocol  urgent  ack  push  reset  syn  fin  \\\n",
       "0  1.015625  ...             2        17       0    0     0      0    0    0   \n",
       "1  1.015625  ...             2        17       0    0     0      0    0    0   \n",
       "2  0.507813  ...             1        17       0    0     0      0    0    0   \n",
       "3  0.507813  ...             1        17       0    0     0      0    0    0   \n",
       "4  0.507813  ...             1        17       0    0     0      0    0    0   \n",
       "\n",
       "   timestamp  label  \n",
       "0      22374      1  \n",
       "1      22374      1  \n",
       "2      22374      1  \n",
       "3      22374      1  \n",
       "4      22374      1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2988506\n",
       "0      91386\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train, Val = sklearn.model_selection.train_test_split(data, test_size=0.9, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    298792\n",
       "0      9197\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2689714\n",
       "0      82189\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Val[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.0\n"
     ]
    }
   ],
   "source": [
    "Attack = Train[Train['label']==1]\n",
    "Normal = Train[Train['label']==0]\n",
    "outlier_fraction = np.ceil(len(Attack)/float(len(Normal)))\n",
    "\n",
    "#Let's print how many more outliers are there in the dataset compared to normal data\n",
    "print(outlier_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307989, 20)\n",
      "(307989,)\n"
     ]
    }
   ],
   "source": [
    "#Let's now split the features and the target ground truth\n",
    "features = [feature for feature in Train.columns.tolist() if feature not in [\"label\"]]\n",
    "target = \"label\"\n",
    "\n",
    "# Define a random state \n",
    "state = np.random.RandomState(42)\n",
    "X_train = Train[features]\n",
    "Y_train = Train[target]\n",
    "\n",
    "X_outliers = state.uniform(low=0, high=1, size=(X_train.shape[0], X_train.shape[1]))\n",
    "# Print the shapes of X & Y\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's initalize some classifiers\n",
    "classifiers = {\n",
    "    \"Isolation Forest\":IsolationForest(n_estimators=100, max_samples=len(X_train), \n",
    "                                       contamination=outlier_fraction,random_state=state, verbose=1),\n",
    "    \"Local Outlier Factor\":LocalOutlierFactor(n_neighbors=20, algorithm='auto', \n",
    "                                              leaf_size=30, metric='minkowski',\n",
    "                                              p=2, metric_params=None, contamination=0.03),\n",
    "    \"Support Vector Machine\":OneClassSVM(kernel='rbf', degree=3, gamma=0.1,nu=0.05, \n",
    "                                         max_iter=-1 )\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Outlier Factor: 291532\n",
      "Accuracy Score :\n",
      "0.053433726529194224\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.89      0.05      9197\n",
      "           1       0.89      0.03      0.05    298792\n",
      "\n",
      "    accuracy                           0.05    307989\n",
      "   macro avg       0.46      0.46      0.05    307989\n",
      "weighted avg       0.87      0.05      0.05    307989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_outliers = len(Attack)\n",
    "for i, (clf_name,clf) in enumerate(classifiers.items()):\n",
    "    #Fit the data and tag outliers\n",
    "    if clf_name == \"Local Outlier Factor\":\n",
    "        continue\n",
    "        y_pred = clf.fit_predict(X_train)\n",
    "        scores_prediction = clf.negative_outlier_factor_\n",
    "    elif clf_name == \"Support Vector Machine\":\n",
    "        clf.fit(X_train)\n",
    "        y_pred = clf.predict(X_train)\n",
    "    else:    \n",
    "        continue\n",
    "        clf.fit(X_train)\n",
    "        scores_prediction = clf.decision_function(X_train)\n",
    "        y_pred = clf.predict(X_train)\n",
    "        \n",
    "    #Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions\n",
    "    y_pred[y_pred == 1] = 0\n",
    "    y_pred[y_pred == -1] = 1\n",
    "    n_errors = (y_pred != Y_train).sum()\n",
    "    # Run Classification Metrics\n",
    "    print(\"{}: {}\".format(clf_name,n_errors))\n",
    "    print(\"Accuracy Score :\")\n",
    "    print(accuracy_score(Y_train,y_pred))\n",
    "    print(\"Classification Report :\")\n",
    "    print(classification_report(Y_train,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_outliers = len(Attack)\n",
    "for i, (clf_name,clf) in enumerate(classifiers.items()):\n",
    "    #Fit the data and tag outliers\n",
    "    if clf_name == \"Local Outlier Factor\":\n",
    "        continue\n",
    "        y_pred = clf.fit_predict(X_train)\n",
    "        scores_prediction = clf.negative_outlier_factor_\n",
    "    elif clf_name == \"Support Vector Machine\":\n",
    "        clf.fit(X_train)\n",
    "        y_pred = clf.predict(X_train)\n",
    "    else:    \n",
    "        continue\n",
    "        clf.fit(X_train)\n",
    "        scores_prediction = clf.decision_function(X_train)\n",
    "        y_pred = clf.predict(X_train)\n",
    "        \n",
    "    #Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions\n",
    "    y_pred[y_pred == 1] = 0\n",
    "    y_pred[y_pred == -1] = 1\n",
    "    n_errors = (y_pred != Y_train).sum()\n",
    "    # Run Classification Metrics\n",
    "    print(\"{}: {}\".format(clf_name,n_errors))\n",
    "    print(\"Accuracy Score :\")\n",
    "    print(accuracy_score(Y_train,y_pred))\n",
    "    print(\"Classification Report :\")\n",
    "    print(classification_report(Y_train,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4d667abc1fd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtsne_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-4d667abc1fd5>\u001b[0m in \u001b[0;36mtsne_plot\u001b[0;34m(x1, y1, name)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#Scale features to improve the training ability of TSNE.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstandard_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdf2_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "def tsne_plot(x1, y1, name=\"graph.png\"):\n",
    "    \n",
    "    #Scale features to improve the training ability of TSNE.\n",
    "    standard_scaler = StandardScaler()\n",
    "    df2_std = standard_scaler.fit_transform(x1)\n",
    "\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    x_test_2d = tsne.fit_transform(df2_std)\n",
    "    \n",
    "    #Build the scatter plot with the two types of transactions.\n",
    "    color_map = {0:'red', 1:'blue'}\n",
    "    plt.figure()\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x = x_test_2d[y1==cl,0], \n",
    "                    y = x_test_2d[y1==cl,1], \n",
    "                    c = color_map[idx], \n",
    "                    label = cl)\n",
    "    plt.xlabel('X in t-SNE')\n",
    "    plt.ylabel('Y in t-SNE')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title('t-SNE visualization of test data')\n",
    "    plt.show()\n",
    "    \n",
    "tsne_plot(X_train[:800], Y_train[:800])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I think training this kind of dataset with autoencoders makes more sense so let's try that\n",
    "\n",
    "## input layer \n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "## encoding part\n",
    "encoded = Dense(100, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoded = Dense(50, activation='relu')(encoded)\n",
    "\n",
    "## decoding part\n",
    "decoded = Dense(50, activation='tanh')(encoded)\n",
    "decoded = Dense(100, activation='tanh')(decoded)\n",
    "\n",
    "## output layer\n",
    "output_layer = Dense(X_train.shape[1], activation='relu')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the mdoel\n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "autoencoder.compile(optimizer=\"adadelta\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's do bit of data transformation for scaling\n",
    "\n",
    "x = X_train\n",
    "y = Y_train\n",
    "\n",
    "x_scale = preprocessing.MinMaxScaler().fit_transform(x.values)\n",
    "x_norm, x_fraud = x_scale[y == 0], x_scale[y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.1175 - val_loss: 0.1175\n",
      "Epoch 2/30\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1169 - val_loss: 0.1169\n",
      "Epoch 3/30\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1162 - val_loss: 0.1162\n",
      "Epoch 4/30\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1156 - val_loss: 0.1156\n",
      "Epoch 5/30\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.1149 - val_loss: 0.1149\n",
      "Epoch 6/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1142 - val_loss: 0.1142\n",
      "Epoch 7/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1135 - val_loss: 0.1135\n",
      "Epoch 8/30\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.1128 - val_loss: 0.1127\n",
      "Epoch 9/30\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1120 - val_loss: 0.1120\n",
      "Epoch 10/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1113 - val_loss: 0.1113\n",
      "Epoch 11/30\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.1106 - val_loss: 0.1106\n",
      "Epoch 12/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1099 - val_loss: 0.1099\n",
      "Epoch 13/30\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.1091 - val_loss: 0.1091\n",
      "Epoch 14/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1084 - val_loss: 0.1084\n",
      "Epoch 15/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1077 - val_loss: 0.1077\n",
      "Epoch 16/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.1069 - val_loss: 0.1069\n",
      "Epoch 17/30\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1062 - val_loss: 0.1062\n",
      "Epoch 18/30\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.1055 - val_loss: 0.1055\n",
      "Epoch 19/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1048 - val_loss: 0.1048\n",
      "Epoch 20/30\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1040 - val_loss: 0.1041\n",
      "Epoch 21/30\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1033 - val_loss: 0.1034\n",
      "Epoch 22/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1026 - val_loss: 0.1026\n",
      "Epoch 23/30\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1019 - val_loss: 0.1019\n",
      "Epoch 24/30\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1012 - val_loss: 0.1012\n",
      "Epoch 25/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1005 - val_loss: 0.1005\n",
      "Epoch 26/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0998 - val_loss: 0.0998\n",
      "Epoch 27/30\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0991 - val_loss: 0.0991\n",
      "Epoch 28/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0984 - val_loss: 0.0984\n",
      "Epoch 29/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0977 - val_loss: 0.0978\n",
      "Epoch 30/30\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0970 - val_loss: 0.0971\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x_norm[0:8000], x_norm[0:8000], \n",
    "                batch_size = 256, epochs = 30, \n",
    "                shuffle = True, validation_split = 0.20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try tp get latent learnt representation by autoencoder\n",
    "hidden_representation = Sequential()\n",
    "hidden_representation.add(autoencoder.layers[0])\n",
    "hidden_representation.add(autoencoder.layers[1])\n",
    "hidden_representation.add(autoencoder.layers[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_hid_rep = hidden_representation.predict(x_norm[:3000])\n",
    "fraud_hid_rep = hidden_representation.predict(x_fraud[:3000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tsne_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6d846d8e2a95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfraud_hid_rep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrep_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtsne_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrep_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"latent_representation.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tsne_plot' is not defined"
     ]
    }
   ],
   "source": [
    "#Let's try to visualize TSNE again for the learnt representation\n",
    "rep_x = np.append(norm_hid_rep, fraud_hid_rep, axis = 0)\n",
    "y_n = np.zeros(norm_hid_rep.shape[0])\n",
    "y_f = np.ones(fraud_hid_rep.shape[0])\n",
    "rep_y = np.append(y_n, y_f)\n",
    "tsne_plot(rep_x, rep_y, \"latent_representation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99       733\n",
      "         1.0       0.99      1.00      0.99       767\n",
      "\n",
      "    accuracy                           0.99      1500\n",
      "   macro avg       0.99      0.99      0.99      1500\n",
      "weighted avg       0.99      0.99      0.99      1500\n",
      "\n",
      "\n",
      "Accuracy Score:  0.9933333333333333\n"
     ]
    }
   ],
   "source": [
    "#Finally we can train a classifier on learnt representations\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(rep_x, rep_y, test_size=0.25)\n",
    "clf = LogisticRegression(solver=\"lbfgs\").fit(train_x, train_y)\n",
    "pred_y = clf.predict(val_x)\n",
    "\n",
    "print (\"\")\n",
    "print (\"Classification Report: \")\n",
    "print (classification_report(val_y, pred_y))\n",
    "\n",
    "print (\"\")\n",
    "print (\"Accuracy Score: \", accuracy_score(val_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
